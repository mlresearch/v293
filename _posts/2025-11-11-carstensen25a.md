---
title: 'Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization'
openreview: CyGwCrE6Go
abstract: 'As model sizes grow, finding efficient and cost-effective hyperparameter
  optimization (HPO) methods becomes increasingly crucial for deep learning pipelines.
  While multi-fidelity HPO (MF-HPO) trades off computational resources required for
  DL training with lower fidelity estimations, existing fidelity sources often fail
  under lower compute and memory constraints. We propose a novel fidelity source:
  the number of layers that are trained or frozen during training. For deep networks,
  this approach offers significant compute and memory savings while preserving rank
  correlations between hyperparameters at low fidelities compared to full model training.
  We demonstrate this in our empirical evaluation across MLPs, ResNets, and Transformers
  and additionally analyze the utility of frozen layers as fidelity in using GPU resources
  as fidelity in HPO, and for a combined MF-HPO with other fidelity sources. This
  contribution opens new applications for MF-HPO with hardware resources as fidelity
  and creates opportunities for improved algorithms navigating joint fidelity spaces.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: carstensen25a
month: 0
tex_title: 'Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization'
firstpage: 4/1
lastpage: 24
page: 4/1-24
order: 4
cycles: false
bibtex_author: Carstensen, Timur and Mallik, Neeratyoy and Hutter, Frank and Rapp,
  Martin
author:
- given: Timur
  family: Carstensen
- given: Neeratyoy
  family: Mallik
- given: Frank
  family: Hutter
- given: Martin
  family: Rapp
date: 2025-11-11
address:
container-title: Proceedings of the Fourth International Conference on Automated Machine
  Learning
volume: '293'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 11
  - 11
pdf: https://raw.githubusercontent.com/mlresearch/v293/main/assets/carstensen25a/carstensen25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
